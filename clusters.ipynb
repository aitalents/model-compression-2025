{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/model-compression/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Основное устройство для оценки: cuda, основной dtype: torch.float16\n",
      "Загрузка процессора для openai/whisper-large-v3...\n",
      "Процессор загружен.\n",
      "Метрики WER и CER загружены.\n",
      "forced_decoder_ids подготовлены.\n",
      "Функции оценки качества и производительности определены.\n",
      "Загрузка датасета mozilla-foundation/common_voice_16_1 для оценки качества (test split)...\n",
      "Загружено 50 сэмплов для оценки качества.\n",
      "Загрузка датасета mozilla-foundation/common_voice_16_1 для замеров производительности (test split)...\n",
      "Загружено 13 аудиодорожек для замеров производительности.\n",
      "\n",
      "--- Первая ячейка: настройка завершена. Можно переходить к кластеризации. ---\n"
     ]
    }
   ],
   "source": [
    "# --- ПЕРВАЯ ЯЧЕЙКА: ОСНОВНАЯ НАСТРОЙКА И ЗАГРУЗКА ---\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "import time\n",
    "import psutil\n",
    "from datasets import load_dataset, Audio\n",
    "import evaluate\n",
    "import os\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import copy # Для копирования модели\n",
    "import numpy as np # Для k-means и работы с весами\n",
    "from sklearn.cluster import KMeans # Для кластеризации\n",
    "\n",
    "# --- 1. Конфигурация ---\n",
    "MODEL_ID = \"openai/whisper-large-v3\"\n",
    "DATASET_ID = \"mozilla-foundation/common_voice_16_1\"\n",
    "DATASET_NAME = \"ru\"\n",
    "DATASET_SPLIT = \"test\" # Для оценки качества\n",
    "# CALIBRATION_SPLIT = \"train\" # Не используется в этой ячейке, но может быть для других\n",
    "NUM_SAMPLES_FOR_QUALITY_TEST = 50\n",
    "NUM_SAMPLES_FOR_TIME_TEST = 10\n",
    "NUM_WARMUP_RUNS = 3\n",
    "# NUM_CALIBRATION_SAMPLES = 20 # Не используется здесь\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "\n",
    "# --- 2. Определение устройства и типа данных ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Для базовой модели и сравнений обычно используется FP16 на GPU или FP32 на CPU\n",
    "# В коде кластеризации мы будем загружать модель в FP32 на CPU для k-means,\n",
    "# а затем переносить на целевое устройство и в целевой dtype (который может быть FP16 на GPU)\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(f\"Основное устройство для оценки: {device}, основной dtype: {torch_dtype}\")\n",
    "\n",
    "# --- 3. Загрузка ПРОЦЕССОРА (нужен для функций оценки) ---\n",
    "print(f\"Загрузка процессора для {MODEL_ID}...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "print(\"Процессор загружен.\")\n",
    "\n",
    "# --- 4. Загрузка МЕТРИК ОЦЕНКИ (нужны для функций оценки) ---\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "print(\"Метрики WER и CER загружены.\")\n",
    "\n",
    "# --- 5. Подготовка FORCED_DECODER_IDS (нужны для функций оценки Whisper) ---\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n",
    "print(\"forced_decoder_ids подготовлены.\")\n",
    "\n",
    "# --- 6. Определение ФУНКЦИЙ ОЦЕНКИ КАЧЕСТВА И ПРОИЗВОДИТЕЛЬНОСТИ ---\n",
    "# Эти функции будут использоваться для оценки как оригинальной, так и кластеризованной модели.\n",
    "\n",
    "def evaluate_quality_whisper(model_to_eval, processor_to_use, dataset_to_eval, num_samples, device_to_use, dtype_to_use, forced_decoder_ids_for_eval):\n",
    "    model_to_eval.to(device_to_use, dtype=dtype_to_use) # Убедимся, что модель на нужном устройстве и в нужном dtype\n",
    "    model_to_eval.eval()\n",
    "    _predictions = []\n",
    "    _references = []\n",
    "    \n",
    "    for i in tqdm(range(min(num_samples, len(dataset_to_eval))), desc=f\"Оценка качества ({str(device_to_use)}, {str(dtype_to_use)})\"):\n",
    "        sample = dataset_to_eval[i]\n",
    "        reference_text = sample[\"sentence\"]\n",
    "        if not reference_text or reference_text.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        raw_audio = sample[\"audio\"][\"array\"]\n",
    "        sampling_rate = sample[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "        if len(raw_audio) == 0:\n",
    "            _predictions.append(\"\")\n",
    "            _references.append(reference_text.lower())\n",
    "            continue\n",
    "        \n",
    "        input_features = processor_to_use(raw_audio, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features\n",
    "        input_features = input_features.to(device_to_use, dtype=dtype_to_use)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model_to_eval.generate(input_features, forced_decoder_ids=forced_decoder_ids_for_eval)\n",
    "        \n",
    "        predicted_text = processor_to_use.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        _predictions.append(predicted_text.strip().lower())\n",
    "        _references.append(reference_text.lower())\n",
    "        del input_features, predicted_ids\n",
    "        if device_to_use.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    _wer, _cer = \"N/A\", \"N/A\"\n",
    "    if _predictions and _references:\n",
    "        _wer = wer_metric.compute(predictions=_predictions, references=_references)\n",
    "        _cer = cer_metric.compute(predictions=_predictions, references=_references)\n",
    "    return _wer, _cer, _predictions, _references\n",
    "\n",
    "def evaluate_performance_whisper(model_to_eval, processor_to_use, audio_list_for_timing, num_warmup, num_test, device_to_use, dtype_to_use, forced_decoder_ids_for_eval):\n",
    "    model_to_eval.to(device_to_use, dtype=dtype_to_use) # Убедимся, что модель на нужном устройстве и в нужном dtype\n",
    "    model_to_eval.eval()\n",
    "    _times = []\n",
    "    _vram_usage_mb, _ram_usage_mb = \"N/A\", \"N/A\"\n",
    "    \n",
    "    desc_perf = f\"Замеры производительности ({str(device_to_use)}, {str(dtype_to_use)})\"\n",
    "\n",
    "    # Прогрев\n",
    "    # print(f\"Прогрев ({desc_perf})...\")\n",
    "    for i in range(min(num_warmup, len(audio_list_for_timing))):\n",
    "        raw_audio = audio_list_for_timing[i]\n",
    "        input_features = processor_to_use(raw_audio, sampling_rate=TARGET_SAMPLE_RATE, return_tensors=\"pt\").input_features.to(device_to_use, dtype=dtype_to_use)\n",
    "        with torch.no_grad():\n",
    "            _ = model_to_eval.generate(input_features, forced_decoder_ids=forced_decoder_ids_for_eval)\n",
    "        del input_features\n",
    "        if device_to_use.type == 'cuda':\n",
    "            torch.cuda.synchronize() # Синхронизация после каждой операции на GPU в прогреве\n",
    "            \n",
    "    if device_to_use.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats(device_to_use) # Сбрасываем память ПОСЛЕ прогрева\n",
    "        torch.cuda.synchronize() # Убедимся, что reset завершен\n",
    "\n",
    "    ps_process = psutil.Process(os.getpid())\n",
    "    # ram_before_mb = ps_process.memory_info().rss / (1024 * 1024) # RAM перед замерами\n",
    "\n",
    "    for i in tqdm(range(min(num_test, len(audio_list_for_timing))), desc=desc_perf):\n",
    "        raw_audio = audio_list_for_timing[i]\n",
    "        input_features = processor_to_use(raw_audio, sampling_rate=TARGET_SAMPLE_RATE, return_tensors=\"pt\").input_features.to(device_to_use, dtype=dtype_to_use)\n",
    "        \n",
    "        if device_to_use.type == 'cuda':\n",
    "            torch.cuda.synchronize() # Синхронизация ПЕРЕД стартом таймера\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ = model_to_eval.generate(input_features, forced_decoder_ids=forced_decoder_ids_for_eval)\n",
    "        \n",
    "        if device_to_use.type == 'cuda':\n",
    "            torch.cuda.synchronize() # Синхронизация ПОСЛЕ завершения операций на GPU\n",
    "        end_time = time.perf_counter()\n",
    "        _times.append((end_time - start_time) * 1000) # ms\n",
    "        \n",
    "        if i == 0 and device_to_use.type == 'cuda': # VRAM на первом реальном замере\n",
    "            _vram_usage_mb = torch.cuda.max_memory_allocated(device_to_use) / (1024 * 1024)\n",
    "        del input_features\n",
    "        if device_to_use.type == 'cuda':\n",
    "            torch.cuda.empty_cache() # Очищаем кэш после каждого инференса\n",
    "\n",
    "    _avg_time_ms = sum(_times) / len(_times) if _times else \"N/A\"\n",
    "    _ram_usage_mb = ps_process.memory_info().rss / (1024 * 1024) # RAM после всех замеров\n",
    "    \n",
    "    return _avg_time_ms, _vram_usage_mb if device_to_use.type == 'cuda' else \"N/A\", _ram_usage_mb\n",
    "\n",
    "print(\"Функции оценки качества и производительности определены.\")\n",
    "\n",
    "# --- 7. ЗАГРУЗКА ДАТАСЕТОВ (чтобы они были доступны для последующих ячеек) ---\n",
    "print(f\"Загрузка датасета {DATASET_ID} для оценки качества ({DATASET_SPLIT} split)...\")\n",
    "quality_dataset = load_dataset(DATASET_ID, DATASET_NAME, split=f\"{DATASET_SPLIT}[:{NUM_SAMPLES_FOR_QUALITY_TEST}]\", trust_remote_code=True)\n",
    "quality_dataset = quality_dataset.cast_column(\"audio\", Audio(sampling_rate=TARGET_SAMPLE_RATE))\n",
    "print(f\"Загружено {len(quality_dataset)} сэмплов для оценки качества.\")\n",
    "\n",
    "print(f\"Загрузка датасета {DATASET_ID} для замеров производительности ({DATASET_SPLIT} split)...\")\n",
    "timing_dataset_raw_obj = load_dataset(DATASET_ID, DATASET_NAME, split=f\"{DATASET_SPLIT}[:{NUM_SAMPLES_FOR_TIME_TEST + NUM_WARMUP_RUNS}]\", trust_remote_code=True)\n",
    "timing_dataset_raw_obj = timing_dataset_raw_obj.cast_column(\"audio\", Audio(sampling_rate=TARGET_SAMPLE_RATE))\n",
    "raw_audio_list_for_timing = [sample[\"audio\"][\"array\"] for sample in timing_dataset_raw_obj]\n",
    "print(f\"Загружено {len(raw_audio_list_for_timing)} аудиодорожек для замеров производительности.\")\n",
    "\n",
    "# --- (ОПЦИОНАЛЬНО) Загрузка базовой модели для сравнения, если нужно ---\n",
    "# Если вы хотите сравнить кластеризованную модель с нетронутой FP16/FP32 моделью в этом же ноутбуке,\n",
    "# вы можете загрузить ее здесь и сохранить.\n",
    "# В коде кластеризации мы загружаем модель заново для чистоты эксперимента,\n",
    "# но для финальной таблицы вам понадобятся baseline-метрики.\n",
    "\n",
    "# print(f\"Загрузка базовой модели {MODEL_ID} для справки...\")\n",
    "# baseline_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=torch_dtype,\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     use_safetensors=True\n",
    "# ).to(device)\n",
    "# baseline_model.eval()\n",
    "# print(\"Базовая модель загружена (если нужна для прямого сравнения в этом ноутбуке).\")\n",
    "\n",
    "print(\"\\n--- Первая ячейка: настройка завершена. Можно переходить к кластеризации. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Кластеризация весов K-Means для openai/whisper-large-v3 ---\n",
      "Создание копии модели openai/whisper-large-v3 для кластеризации на cuda с dtype torch.float16...\n",
      "Копия модели создана и перенесена.\n",
      "Применение кластеризации (n_clusters=32) к слоям типа [<class 'torch.nn.modules.linear.Linear'>]...\n",
      "Кластеризация весов завершена.\n",
      "\n",
      "Проведение оценки качества (Кластеризованная модель)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка качества (cuda, torch.float16):   0%|          | 0/50 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Оценка качества (cuda, torch.float16): 100%|██████████| 50/50 [00:23<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество (WER) Кластеризованная модель: 0.1316\n",
      "Качество (CER) Кластеризованная модель: 0.0464\n",
      "\n",
      "Проведение замеров производительности (Кластеризованная модель)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Замеры производительности (cuda, torch.float16): 100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Результаты: Кластеризация весов (K-Means) ---\n",
      "Модель: openai/whisper-large-v3\n",
      "Метод: Кластеризация K-Means (n_clusters=32 для Linear слоев)\n",
      "Dtype: torch.float16\n",
      "Устройство: cuda\n",
      "Размер кластеризованных параметров (оригинальный, MB): 2926.63\n",
      "Размер модели (теоретический после кластеризации, MB): 1463.38 (только кластеризованные слои)\n",
      "Размер модели (фактическое хранение state_dict, MB): 2943.97\n",
      "Время инференса (CUDA, ms): 557.09\n",
      "Использование VRAM (MB): 3204.53\n",
      "Использование RAM (MB): 12402.24\n",
      "Качество (WER): 0.1316\n",
      "Качество (CER): 0.0464\n",
      "\n",
      "Результаты для таблицы (Кластеризация):\n",
      "{'method': 'Clustering K-Means (k=32)', 'model_id': 'openai/whisper-large-v3', 'dtype': 'torch.float16', 'device': 'cuda', 'model_size_mb': '1463.38 (theor.) / 2943.97 (actual st_dict)', 'time_ms': '557.09', 'vram_mb': '3204.53', 'ram_mb': '12402.24', 'wer': '0.1316', 'cer': '0.0464'}\n"
     ]
    }
   ],
   "source": [
    "# --- ЯЧЕЙКА ДЛЯ КЛАСТЕРИЗАЦИИ ВЕСОВ (K-MEANS) ---\n",
    "# Предполагается, что переменные из ПЕРВОЙ ячейки (конфигурация, пути, processor, etc.) доступны.\n",
    "# Функции evaluate_quality_whisper и evaluate_performance_whisper также должны быть определены ранее.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "print(f\"--- Кластеризация весов K-Means для {MODEL_ID} ---\")\n",
    "\n",
    "# 1. Параметры кластеризации\n",
    "N_CLUSTERS = 32 # Количество кластеров для весов каждого слоя. Можете поэкспериментировать.\n",
    "# Будем кластеризовать только линейные слои (самые большие по количеству весов в трансформерах)\n",
    "LAYERS_TO_CLUSTER = [torch.nn.Linear]\n",
    "\n",
    "# 2. Загрузка \"чистой\" модели или создание глубокой копии\n",
    "# Важно работать с копией, чтобы не изменять оригинальную FP16 модель перманентно.\n",
    "# Используем устройство и dtype из первой ячейки для консистентности.\n",
    "cluster_device = device\n",
    "cluster_dtype = torch_dtype\n",
    "\n",
    "print(f\"Создание копии модели {MODEL_ID} для кластеризации на {cluster_device} с dtype {cluster_dtype}...\")\n",
    "# Сначала загрузим на CPU в FP32, чтобы избежать проблем с k-means на GPU/FP16, затем скопируем и перенесем.\n",
    "model_fp32_cpu_for_clustering = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    low_cpu_mem_usage=True, # Экономия RAM при загрузке\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float32 # Загружаем в FP32\n",
    ").to(\"cpu\")\n",
    "\n",
    "model_to_cluster = copy.deepcopy(model_fp32_cpu_for_clustering)\n",
    "model_to_cluster.to(cluster_device, dtype=cluster_dtype) # Переносим на нужное устройство и в нужный dtype\n",
    "model_to_cluster.eval()\n",
    "del model_fp32_cpu_for_clustering # Освобождаем память\n",
    "gc.collect()\n",
    "if cluster_device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Копия модели создана и перенесена.\")\n",
    "\n",
    "\n",
    "# 3. Функция для применения кластеризации к слою\n",
    "def cluster_layer_weights(module, n_clusters):\n",
    "    if not hasattr(module, 'weight') or module.weight is None:\n",
    "        return 0, 0\n",
    "\n",
    "    original_weights = module.weight.data.cpu().numpy().astype(np.float32) # K-Means лучше работает с FP32 CPU\n",
    "    original_shape = original_weights.shape\n",
    "    \n",
    "    # K-means ожидает 2D массив [n_samples, n_features]\n",
    "    # Если веса многомерные (например, для сверток, но мы здесь их не трогаем), их нужно решейпить.\n",
    "    # Для nn.Linear веса уже 2D [out_features, in_features]\n",
    "    weights_flat = original_weights.reshape(-1, 1) # K-means для одномерных данных (каждый вес - точка)\n",
    "\n",
    "    if weights_flat.shape[0] < n_clusters:\n",
    "        # print(f\"  Количество весов ({weights_flat.shape[0]}) меньше числа кластеров ({n_clusters}). Пропуск слоя.\")\n",
    "        return 0,0 # Невозможно кластеризовать\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto', algorithm='lloyd') # n_init='auto' для подавления warning\n",
    "    kmeans.fit(weights_flat)\n",
    "    \n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Заменяем веса на значения центроидов\n",
    "    weights_clustered_flat = centroids[labels].reshape(-1)\n",
    "    weights_clustered = weights_clustered_flat.reshape(original_shape)\n",
    "    \n",
    "    # Обновляем веса слоя\n",
    "    module.weight.data = torch.from_numpy(weights_clustered).to(module.weight.device, dtype=module.weight.dtype)\n",
    "    \n",
    "    # Подсчет теоретического размера: словарь центроидов + индексы\n",
    "    # Размер центроидов: n_clusters * sizeof(float)\n",
    "    # Размер индексов: num_weights * sizeof(индекс) (например, ceil(log2(n_clusters)) бит на индекс)\n",
    "    size_of_float = 4 # байты для FP32 центроидов\n",
    "    bits_per_index = np.ceil(np.log2(n_clusters)).astype(int)\n",
    "    bytes_per_index = (bits_per_index + 7) // 8 # округляем до байтов\n",
    "\n",
    "    theoretical_size_centroids = n_clusters * size_of_float\n",
    "    theoretical_size_indices = weights_flat.shape[0] * bytes_per_index\n",
    "    \n",
    "    return theoretical_size_centroids, theoretical_size_indices\n",
    "\n",
    "\n",
    "# 4. Применение кластеризации к выбранным слоям модели\n",
    "print(f\"Применение кластеризации (n_clusters={N_CLUSTERS}) к слоям типа {LAYERS_TO_CLUSTER}...\")\n",
    "total_theoretical_size_centroids = 0\n",
    "total_theoretical_size_indices = 0\n",
    "total_original_size_of_clustered_params = 0 # Для сравнения с теоретическим\n",
    "bytes_per_original_param = 4 if model_to_cluster.dtype == torch.float32 else 2 # Используем dtype модели на устройстве\n",
    "\n",
    "for module_name, module in model_to_cluster.named_modules():\n",
    "    for layer_type in LAYERS_TO_CLUSTER:\n",
    "        if isinstance(module, layer_type):\n",
    "            # print(f\"Кластеризация слоя: {module_name}\")\n",
    "            current_params = module.weight.data.numel()\n",
    "            size_c, size_i = cluster_layer_weights(module, N_CLUSTERS)\n",
    "            if size_c > 0: # Если кластеризация была применена\n",
    "                 total_theoretical_size_centroids += size_c\n",
    "                 total_theoretical_size_indices += size_i\n",
    "                 total_original_size_of_clustered_params += current_params * bytes_per_original_param\n",
    "            break # Переходим к следующему именованному модулю\n",
    "\n",
    "print(\"Кластеризация весов завершена.\")\n",
    "theoretical_clustered_size_mb = (total_theoretical_size_centroids + total_theoretical_size_indices) / (1024 * 1024)\n",
    "original_size_of_clustered_params_mb = total_original_size_of_clustered_params / (1024 * 1024)\n",
    "\n",
    "# 5. Подготовка данных (если не были загружены ранее)\n",
    "if 'quality_dataset' not in locals() or 'raw_audio_list_for_timing' not in locals():\n",
    "    print(\"Перезагрузка датасетов...\")\n",
    "    quality_dataset = load_dataset(DATASET_ID, DATASET_NAME, split=f\"{DATASET_SPLIT}[:{NUM_SAMPLES_FOR_QUALITY_TEST}]\", trust_remote_code=True)\n",
    "    quality_dataset = quality_dataset.cast_column(\"audio\", Audio(sampling_rate=TARGET_SAMPLE_RATE))\n",
    "    timing_dataset_raw = load_dataset(DATASET_ID, DATASET_NAME, split=f\"{DATASET_SPLIT}[:{NUM_SAMPLES_FOR_TIME_TEST + NUM_WARMUP_RUNS}]\", trust_remote_code=True)\n",
    "    timing_dataset_raw = timing_dataset_raw.cast_column(\"audio\", Audio(sampling_rate=TARGET_SAMPLE_RATE))\n",
    "    raw_audio_list_for_timing = [sample[\"audio\"][\"array\"] for sample in timing_dataset_raw]\n",
    "    print(\"Датасеты перезагружены.\")\n",
    "\n",
    "# 6. Проведение замеров для кластеризованной модели\n",
    "# forced_decoder_ids и processor должны быть доступны из первой ячейки\n",
    "\n",
    "print(\"\\nПроведение оценки качества (Кластеризованная модель)...\")\n",
    "clustered_wer, clustered_cer, _, _ = evaluate_quality_whisper(\n",
    "    model_to_cluster, processor, quality_dataset, NUM_SAMPLES_FOR_QUALITY_TEST,\n",
    "    cluster_device, cluster_dtype, forced_decoder_ids\n",
    ")\n",
    "print(f\"Качество (WER) Кластеризованная модель: {clustered_wer if isinstance(clustered_wer, str) else clustered_wer:.4f}\")\n",
    "print(f\"Качество (CER) Кластеризованная модель: {clustered_cer if isinstance(clustered_cer, str) else clustered_cer:.4f}\")\n",
    "\n",
    "print(\"\\nПроведение замеров производительности (Кластеризованная модель)...\")\n",
    "clustered_time_ms, clustered_vram_mb, clustered_ram_mb = evaluate_performance_whisper(\n",
    "    model_to_cluster, processor, raw_audio_list_for_timing, NUM_WARMUP_RUNS, NUM_SAMPLES_FOR_TIME_TEST,\n",
    "    cluster_device, cluster_dtype, forced_decoder_ids\n",
    ")\n",
    "\n",
    "# Размер модели \"на диске\" (state_dict) после такой кластеризации не изменится,\n",
    "# так как мы просто заменили значения весов. Реальное сжатие требует другого формата хранения.\n",
    "# Но мы можем использовать теоретический размер.\n",
    "num_params_total = sum(p.numel() for p in model_to_cluster.parameters()) # Все параметры\n",
    "clustered_model_size_actual_storage_mb = (num_params_total * bytes_per_original_param) / (1024*1024)\n",
    "\n",
    "\n",
    "# --- 7. Вывод результатов для Кластеризации ---\n",
    "print(\"\\n--- Результаты: Кластеризация весов (K-Means) ---\")\n",
    "print(f\"Модель: {MODEL_ID}\")\n",
    "print(f\"Метод: Кластеризация K-Means (n_clusters={N_CLUSTERS} для Linear слоев)\")\n",
    "print(f\"Dtype: {cluster_dtype}\")\n",
    "print(f\"Устройство: {cluster_device}\")\n",
    "print(f\"Размер кластеризованных параметров (оригинальный, MB): {original_size_of_clustered_params_mb:.2f}\")\n",
    "print(f\"Размер модели (теоретический после кластеризации, MB): {theoretical_clustered_size_mb:.2f} (только кластеризованные слои)\")\n",
    "print(f\"Размер модели (фактическое хранение state_dict, MB): {clustered_model_size_actual_storage_mb:.2f}\")\n",
    "print(f\"Время инференса ({cluster_device.type.upper()}, ms): {clustered_time_ms if isinstance(clustered_time_ms, str) else f'{clustered_time_ms:.2f}'}\")\n",
    "if cluster_device.type == 'cuda':\n",
    "    print(f\"Использование VRAM (MB): {clustered_vram_mb if isinstance(clustered_vram_mb, str) else f'{clustered_vram_mb:.2f}'}\")\n",
    "print(f\"Использование RAM (MB): {clustered_ram_mb if isinstance(clustered_ram_mb, str) else f'{clustered_ram_mb:.2f}'}\")\n",
    "print(f\"Качество (WER): {clustered_wer if isinstance(clustered_wer, str) else f'{clustered_wer:.4f}'}\")\n",
    "print(f\"Качество (CER): {clustered_cer if isinstance(clustered_cer, str) else f'{clustered_cer:.4f}'}\")\n",
    "\n",
    "results_clustering = {\n",
    "    \"method\": f\"Clustering K-Means (k={N_CLUSTERS})\",\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"dtype\": str(cluster_dtype),\n",
    "    \"device\": str(cluster_device),\n",
    "    \"model_size_mb\": f\"{theoretical_clustered_size_mb:.2f} (theor.) / {clustered_model_size_actual_storage_mb:.2f} (actual st_dict)\",\n",
    "    \"time_ms\": f\"{clustered_time_ms:.2f}\" if isinstance(clustered_time_ms, (int, float)) else clustered_time_ms,\n",
    "    \"vram_mb\": f\"{clustered_vram_mb:.2f}\" if isinstance(clustered_vram_mb, (int, float)) else clustered_vram_mb,\n",
    "    \"ram_mb\": f\"{clustered_ram_mb:.2f}\" if isinstance(clustered_ram_mb, (int, float)) else clustered_ram_mb,\n",
    "    \"wer\": f\"{clustered_wer:.4f}\" if isinstance(clustered_wer, (int, float)) else clustered_wer,\n",
    "    \"cer\": f\"{clustered_cer:.4f}\" if isinstance(clustered_cer, (int, float)) else clustered_cer,\n",
    "}\n",
    "print(\"\\nРезультаты для таблицы (Кластеризация):\")\n",
    "print(results_clustering)\n",
    "\n",
    "# Очистка\n",
    "del model_to_cluster\n",
    "gc.collect()\n",
    "if cluster_device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
