# model-compression-2025

Репозиторий курса по сжатию и ускорению моделей машинного обучения.
ИТМО 2025, направление магистратуры Искуственный интеллект.

**Сравнительная таблица: До и После Кластеризации Весов**

| Характеристика                                     | `openai/whisper-large-v3` (FP16 Baseline) | `openai/whisper-large-v3` (После кластеризации K-Means, k=32, FP16) | Изменение (%)                                                                 |
| :------------------------------------------------- | :---------------------------------------- | :-------------------------------------------------------------------- | :---------------------------------------------------------------------------- |
| **Метод**                                          | FP16 (GPU Baseline)                       | Clustering K-Means (k=32)                                             | -                                                                             |
| **Размер модели (факт. `state_dict`, MB)**         | 2940.31                                   | 2943.97                                                               | +0.12% (незначительное изменение, ожидаемо)                                   |
| **Размер модели (теоретич. класт. части, MB)**     | N/A                                       | 1463.38                                                               | *Показывает потенциал сжатия для кластеризованных весов*                      |
| **Время инференса (GPU, ms)**                     | 540.48                                    | 557.09                                                                | +3.07% (небольшое замедление, ожидаемо без спец. поддержки)                    |
| **Использование VRAM (MB)**                        | 3203.10                                   | 3204.53                                                               | +0.04% (незначительное изменение)                                               |
| **Использование RAM (MB) (пиковое всего процесса)** | 40564.33                                  | 12402.24                                                              | -69.45% (значительное снижение, вероятно, связано с управлением памятью в ячейке) |
| **Качество (WER)**                                 | 0.1468                                    | 0.1316                                                                | **-10.35%** (Улучшение!)                                                      |
| **Качество (CER)**                                 | 0.0490                                    | 0.0464                                                                | **-5.31%** (Улучшение!)                                                       |

**Примечания к таблице:**

*   **Размер модели (факт. `state_dict`):** Как и ожидалось, фактический размер файла `state_dict` почти не изменился, так как мы только заменили значения весов, а не структуру или плотность хранения. Небольшое увеличение может быть связано с нюансами сохранения чисел с плавающей запятой.
*   **Размер модели (теоретич. класт. части):** Это значение показывает, насколько можно было бы сжать *только те части весов, которые были кластеризованы*, если бы использовался оптимальный формат хранения (словари центроидов + индексы). Оно не отражает общий размер модели, так как не включает некластеризованные параметры.
*   **Время инференса (GPU):** Небольшое замедление (~3%) после кластеризации является ожидаемым, поскольку стандартные операции PyTorch не оптимизированы для работы с весами, которые были "огрублены" до значений центроидов, и нет специальной поддержки для ускорения на основе этой структуры без кастомных ядер.
*   **Использование RAM:** Такое значительное снижение пикового потребления RAM для процесса, скорее всего, не является прямым следствием *самой кластеризации*, а больше связано с тем, как модель загружалась, копировалась и очищалась в ячейке для кластеризации по сравнению с ячейкой для FP16 baseline. Например, использование `copy.deepcopy` с последующим `del` оригинальной CPU-модели могло более эффективно освободить память, чем простой запуск FP16-ячейки. Это требует более детального анализа управления памятью в каждом конкретном запуске, чтобы делать выводы именно о влиянии метода.
*   **Качество (WER/CER):** Улучшение качества после кластеризации — это очень интересный и положительный результат! Иногда удаление "избыточности" или "шума" в весах таким способом может привести к небольшой регуляризации и улучшению на конкретном тестовом наборе. Однако, это не всегда гарантировано, часто ожидается небольшое падение.


*План курса*

    Пара 3 - Кластеризация весов моделей.
        1. Что такое кластеризация весов?
            - Идея: заменить уникальные веса модели на меньший набор центроидов.
            - Чем-то похоже на квантизацию, но с более сложной обработкой.
            - Сильнее сжимает, но требует дополнительной декомпрессии на инференсе.
	    2.	Как работает кластеризация?
	        - Использование k-means для группировки весов.
	        - Заменяем веса центроидами, храним индексы.
	        - Гибридный подход: кластеризация + квантизация.
	    3.	Где применяется?
	        - Чаще встречается в CV (сверточные сети, MobileNet).
	        - В NLP используется реже из-за потери точности и высокого влияния на активации.
	        - Возможные кейсы для NLP: кластеризация в self-attention блоках.
	    5.	Инструменты для кластеризации
	        - torch.nn.utils.prune + k-means.
	        - TensorFlow Model Optimization Toolkit (TFMOT).
        6. Практика
            1. Готовим окружение
	        2.	Применяем кластеризацию к весам
	            - Запускаем k-means на слоях модели.
	            - Создаём матрицу центроидов и индексов.
	        3.	Оцениваем влияние на производительность
	            - Время инференса до/после.
	            - Изменение памяти (RAM/VRAM).
	            - Насколько ухудшилось качество (accuracy, PPL).
	        4.	Сравнение с квантизацией
	            - В каких случаях кластеризация даёт лучший результат.
	            - Можно ли комбинировать методы?
	        5.	Записываем результаты в таблицу
	        6.	Домашнее задание
	            Попробовать самостоятельно реализовать кластеризацию весов для своей модели.
                Резльтаты занести в таблицу и скинуть pull request с результатами и код кластеризации в ветку занятия

### Презентации
[Занятие 3 Кластеризация](https://docs.google.com/presentation/d/1Cjqeu4SxZuUteqSc6xaUMOePWA2H2hdpANJ5_p7kFB8/edit#slide=id.g1e7daee4ab9_0_116)
[Статья про метод кластеризации](https://arxiv.org/pdf/1510.00149)
