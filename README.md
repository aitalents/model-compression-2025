# model-compression-2025

Репозиторий курса по сжатию и ускорению моделей машинного обучения.
ИТМО 2025, направление магистратуры Искуственный интеллект.

## Задание


*План*

    Пара 7 - Примененеие компрессии в реальных задачах.
    Разбор реального примера оптимизации моделей
	Разбор задания финального проекта
    Практика - Как запустить финальные проект
    ДЗ: Оптимизировать модели и улучшить метрики производительности в финальном проекте, создав Pull Request.
        1. сделать Форк данного репозитория, ветки lesson-7-final-task
        2. внести изменения в файл solution/infrastructure/models.py class TransformerTextClassificationModel
        3. проверить локально сборку образа и запуск контейнера командами
            - `docker build -t lesson-7 `
            - `docker run -ti -p 8080:8080 -v $PWD/:/src lesson-7:latest`
            - в случае необходимости внести изменения в requirements.txt и Dockerfile
            - пример курла запроса находится в solution/README.md
        3. В данном классе реализация запуска моделей без каких-либо оптимизаций
        4. Вам нужно применить к ним любые оптимизации
        5. Закоммитить изменения в свою ветку
        6. Сделать Pull Request из своего репозитория ветки lesson-7-final-task в данный репозиторий в ветку lesson-7-final-task
            - в названии пулл реквеста указать команду
            - в описании написать какие оптимизации применили


## Решение
Используем ONNXRuntime из Optimum, чтобы ускорить основные модели.  
При инициализации выполним конвертацию и экспорт:
```python
self.model = ORTModelForSequenceClassification.from_pretrained(
    self.model_path,
    export=True,
    provider="CUDAExecutionProvider",
    use_io_binding=True
)
```
А дальше нам остаётся просто использовать модель с выбранным Provider'ом. Это достаточно простая оптимизация, но на практике она очень удобна и полезна.

## Тестирование
### Устройство
CPU: I7 10750H  
GPU: GTX 1650 TI 4 GB  
RAM: 32 GB DDRX4  
При запуске в WSL модели и контейнеры заполняют VRAM и RAM на 96% и 95% соответственно.

### Результаты
Т.к. нам не удалось найти в репозитории конфиг дэшборда Grafana, при запуске она оказывается пустой. Из-за этого при оценке скорости мы полагаемся на отчёты k6.  
Примечание: stress_spike_test не работал в обоих сценариях, вероятно из-за ограничений памяти системы.

До оптимизации:

![Before optimisation (vanilla pytorch)](img/vanilla.png "Before optimisation (vanilla pytorch)")

После оптимизации:

![Before optimisation (vanilla pytorch)](img/optimised.png "Before optimisation (vanilla pytorch)")


**Результат**: прирост с 114 до 132 итераций, то есть +15.8% скорости.