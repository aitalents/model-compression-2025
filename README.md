# Отчет по домашнему заданию 5: Экспорт моделей в различные форматы


## Результаты сравнения

| Format            | Inf_CPU (ms) | Inf_GPU (ms) | RAM (MB)   | VRAM (MB)  | File Size (MB) |
|-------------------|--------------|--------------|------------|------------|----------------|
| PyTorch-CPU       | 23.09        | N/A          | 7664.29    | N/A        | N/A            |
| PyTorch-GPU       | N/A          | 3.92         | N/A        | 119.13     | N/A            |
| TorchScript-CPU   | 23.49        | N/A          | 7683.75    | N/A        | 98.06          |
| TorchScript-GPU   | N/A          | 2.98         | N/A        | 216.86     | 98.06          |
| ONNX-CPU          | 8.96         | N/A          | 7869.72    | N/A        | 97.41          |
| ONNX-GPU          | N/A          | 8.75         | N/A        | 205.53     | 97.41          |
| TensorRT-GPU      | N/A          | **0.53**     | N/A        | 206.11     | 75.18          |
| OpenVINO-CPU      | 10.18        | N/A          | 8131.96    | N/A        | 97.73          |

## Ключевые выводы

### Скорость инференса
- **GPU-режим**:
  - TensorRT-GPU показал **7.4x ускорение** относительно оригинальной PyTorch-GPU модели
  - TorchScript-GPU дал 1.3x ускорение
- **CPU-режим**:
  - ONNX-CPU обеспечил **2.6x ускорение** относительно оригинальной PyTorch-CPU
  - OpenVINO-CPU показал 2.3x ускорение

### Потребление памяти
- Для GPU:
  - TensorRT требует на **73% больше VRAM**, чем оригинальная модель
  - TorchScript-GPU потребляет почти вдвое больше VRAM
- Для CPU:
  - Оптимизированные форматы увеличивают RAM-потребление на 2-6%

### Размер модели
- TensorRT показал **на 23% меньший размер** файла по сравнению с ONNX/TorchScript
- Все экспортированные форматы имеют сравнимый размер (~97-98 MB), кроме TensorRT

### Лучшие результаты:  
**TensorRT-GPU** (0.53 ms) - абсолютный рекордсмен по скорости  
**ONNX-CPU** (8.96 ms) - оптимальный выбор для CPU-инференса
