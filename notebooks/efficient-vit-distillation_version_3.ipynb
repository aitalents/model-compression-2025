{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96fa72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:08:10.569978Z",
     "iopub.status.busy": "2025-04-12T10:08:10.569414Z",
     "iopub.status.idle": "2025-04-12T10:08:23.417266Z",
     "shell.execute_reply": "2025-04-12T10:08:23.416582Z"
    },
    "papermill": {
     "duration": 12.853802,
     "end_time": "2025-04-12T10:08:23.418827",
     "exception": false,
     "start_time": "2025-04-12T10:08:10.565025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cea8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:08:23.427932Z",
     "iopub.status.busy": "2025-04-12T10:08:23.427559Z",
     "iopub.status.idle": "2025-04-12T10:08:23.592363Z",
     "shell.execute_reply": "2025-04-12T10:08:23.591664Z"
    },
    "papermill": {
     "duration": 0.16966,
     "end_time": "2025-04-12T10:08:23.593485",
     "exception": false,
     "start_time": "2025-04-12T10:08:23.423825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/imagenetmini-1000/imagenet-mini\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"ifigotin/imagenetmini-1000\")\n",
    "path += \"/imagenet-mini\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed61893f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:08:23.599985Z",
     "iopub.status.busy": "2025-04-12T10:08:23.599789Z",
     "iopub.status.idle": "2025-04-12T10:08:25.689559Z",
     "shell.execute_reply": "2025-04-12T10:08:25.688975Z"
    },
    "papermill": {
     "duration": 2.094268,
     "end_time": "2025-04-12T10:08:25.690731",
     "exception": false,
     "start_time": "2025-04-12T10:08:23.596463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48ef0daa0ef4ef9b87481dce0959857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51afa35b12e49d4a7fea522ed38ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/36.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_model = timm.create_model('efficientvit_b3.r256_in1k', pretrained=True)\n",
    "student_model = timm.create_model('efficientvit_b1.r256_in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb994022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:08:25.698331Z",
     "iopub.status.busy": "2025-04-12T10:08:25.697769Z",
     "iopub.status.idle": "2025-04-12T10:08:25.702321Z",
     "shell.execute_reply": "2025-04-12T10:08:25.701829Z"
    },
    "papermill": {
     "duration": 0.009223,
     "end_time": "2025-04-12T10:08:25.703334",
     "exception": false,
     "start_time": "2025-04-12T10:08:25.694111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_imagenet_mini(dataset_path, model, split):\n",
    "    config = resolve_data_config({}, model=model)\n",
    "    transform = create_transform(**config)\n",
    "\n",
    "    print(transform)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.2,\n",
    "        ),\n",
    "        transforms.GaussianBlur(\n",
    "            kernel_size=3,\n",
    "        ),\n",
    "        transform,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(dataset_path, split),\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dc2062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:08:25.711333Z",
     "iopub.status.busy": "2025-04-12T10:08:25.710814Z",
     "iopub.status.idle": "2025-04-12T10:09:01.156863Z",
     "shell.execute_reply": "2025-04-12T10:09:01.156256Z"
    },
    "papermill": {
     "duration": 35.450775,
     "end_time": "2025-04-12T10:09:01.158180",
     "exception": false,
     "start_time": "2025-04-12T10:08:25.707405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(256, 256))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(256, 256))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "original_dataset = load_imagenet_mini(path, teacher_model, 'train')\n",
    "\n",
    "train_dataset, val_dataset = random_split(original_dataset, [0.8, 0.2])\n",
    "test_dataset = load_imagenet_mini(path, teacher_model, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36346983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:09:01.166542Z",
     "iopub.status.busy": "2025-04-12T10:09:01.166213Z",
     "iopub.status.idle": "2025-04-12T10:09:01.171142Z",
     "shell.execute_reply": "2025-04-12T10:09:01.170559Z"
    },
    "papermill": {
     "duration": 0.010018,
     "end_time": "2025-04-12T10:09:01.172182",
     "exception": false,
     "start_time": "2025-04-12T10:09:01.162164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4c693f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:09:01.179111Z",
     "iopub.status.busy": "2025-04-12T10:09:01.178926Z",
     "iopub.status.idle": "2025-04-12T10:09:01.186285Z",
     "shell.execute_reply": "2025-04-12T10:09:01.185624Z"
    },
    "papermill": {
     "duration": 0.012085,
     "end_time": "2025-04-12T10:09:01.187303",
     "exception": false,
     "start_time": "2025-04-12T10:09:01.175218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    student_model: nn.Module,\n",
    "    teacher_model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    distill_criterion: nn.Module,\n",
    "    alpha: float,\n",
    "    device: str,\n",
    "):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    loss_accum = 0\n",
    "\n",
    "    for img_batch, targets in tqdm(train_loader, desc='Training model'):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img_batch = img_batch.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        student_output = student_model(img_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher_model(img_batch)\n",
    "\n",
    "        loss = alpha * criterion(student_output, targets) + (1 - alpha) * distill_criterion(student_output, teacher_output)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "    return loss_accum / len(train_loader)\n",
    "\n",
    "\n",
    "def validate_model(\n",
    "    student_model: nn.Module,\n",
    "    teacher_model: nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    distill_criterion: nn.Module,\n",
    "    alpha: float,\n",
    "    device: str,\n",
    "):\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    loss_accum = 0\n",
    "\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    for img_batch, targets in tqdm(val_loader, desc='Validating model'):\n",
    "        img_batch = img_batch.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            student_output = student_model(img_batch)\n",
    "            teacher_output = teacher_model(img_batch)\n",
    "            \n",
    "            loss = alpha * criterion(student_output, targets) + (1 - alpha) * distill_criterion(student_output, teacher_output)\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "        \n",
    "        preds = student_output.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        ground_truth.extend(targets.cpu().numpy().tolist())\n",
    "\n",
    "    return loss_accum / len(val_loader), f1_score(ground_truth, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a35347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:09:01.193899Z",
     "iopub.status.busy": "2025-04-12T10:09:01.193690Z",
     "iopub.status.idle": "2025-04-12T10:09:01.197527Z",
     "shell.execute_reply": "2025-04-12T10:09:01.196866Z"
    },
    "papermill": {
     "duration": 0.008267,
     "end_time": "2025-04-12T10:09:01.198529",
     "exception": false,
     "start_time": "2025-04-12T10:09:01.190262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, T):\n",
    "    soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "    soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "    return torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b928855b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T10:09:01.205415Z",
     "iopub.status.busy": "2025-04-12T10:09:01.204940Z",
     "iopub.status.idle": "2025-04-12T11:17:02.242697Z",
     "shell.execute_reply": "2025-04-12T11:17:02.241625Z"
    },
    "papermill": {
     "duration": 4081.042681,
     "end_time": "2025-04-12T11:17:02.244213",
     "exception": false,
     "start_time": "2025-04-12T10:09:01.201532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 435/435 [11:15<00:00,  1.55s/it]\n",
      "Validating model: 100%|██████████| 109/109 [02:40<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Train Loss: 0.4984 Val Loss: 0.51571 F1: 0.82394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 435/435 [10:52<00:00,  1.50s/it]\n",
      "Validating model: 100%|██████████| 109/109 [02:34<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2 Train Loss: 0.35717 Val Loss: 0.4913 F1: 0.82964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 435/435 [11:02<00:00,  1.52s/it]\n",
      "Validating model: 100%|██████████| 109/109 [02:32<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3 Train Loss: 0.31157 Val Loss: 0.49295 F1: 0.82007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 435/435 [10:55<00:00,  1.51s/it]\n",
      "Validating model: 100%|██████████| 109/109 [02:33<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4 Train Loss: 0.28417 Val Loss: 0.51611 F1: 0.81139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 435/435 [11:00<00:00,  1.52s/it]\n",
      "Validating model: 100%|██████████| 109/109 [02:33<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5 Train Loss: 0.26556 Val Loss: 0.48874 F1: 0.82047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "learning_rate = 1e-4\n",
    "alpha = 0.2\n",
    "distill_temp = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "class_loss = nn.CrossEntropyLoss()\n",
    "distill_loss = lambda x, y: distillation_loss(x, y, distill_temp)\n",
    "best_score = 0\n",
    "\n",
    "student_model.to(device)\n",
    "teacher_model.to(device)\n",
    "\n",
    "for epoch_ind in range(1, epoch_num + 1):\n",
    "    train_loss = train_one_epoch(student_model, teacher_model, train_loader, optimizer, class_loss, distill_loss, alpha, device)\n",
    "    val_loss, f1_score_val = validate_model(student_model, teacher_model, val_loader, class_loss, distill_loss, alpha, device)\n",
    "\n",
    "    print(f'Epoch #{epoch_ind} Train Loss: {round(train_loss, 5)} Val Loss: {round(val_loss, 5)} F1: {round(f1_score_val, 5)}')\n",
    "\n",
    "    if f1_score_val > best_score:\n",
    "        best_score = f1_score_val\n",
    "        torch.save(student_model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c7fc1",
   "metadata": {
    "papermill": {
     "duration": 0.190236,
     "end_time": "2025-04-12T11:17:02.559401",
     "exception": false,
     "start_time": "2025-04-12T11:17:02.369165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf6bf0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:02.848706Z",
     "iopub.status.busy": "2025-04-12T11:17:02.847855Z",
     "iopub.status.idle": "2025-04-12T11:17:08.475166Z",
     "shell.execute_reply": "2025-04-12T11:17:08.474124Z"
    },
    "papermill": {
     "duration": 5.759492,
     "end_time": "2025-04-12T11:17:08.476666",
     "exception": false,
     "start_time": "2025-04-12T11:17:02.717174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\r\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: gputil\r\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=2b392766d7425374edb4d44bb94a1da578d87e0eecfca70db53bea7a58ffa307\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\r\n",
      "Successfully built gputil\r\n",
      "Installing collected packages: gputil\r\n",
      "Successfully installed gputil-1.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18efe7e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:08.695859Z",
     "iopub.status.busy": "2025-04-12T11:17:08.695570Z",
     "iopub.status.idle": "2025-04-12T11:17:08.719979Z",
     "shell.execute_reply": "2025-04-12T11:17:08.719237Z"
    },
    "papermill": {
     "duration": 0.134887,
     "end_time": "2025-04-12T11:17:08.721259",
     "exception": false,
     "start_time": "2025-04-12T11:17:08.586372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import timm\n",
    "import psutil\n",
    "import os\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "from torch.amp import autocast\n",
    "from torchvision import datasets, transforms\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def print_memory_usage(label=\"\"):\n",
    "    \"\"\"Выводит использование памяти в мегабайтах\"\"\"\n",
    "    if label:\n",
    "        print(f\"\\n--- Memory Usage ({label}) ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Memory Usage ---\")\n",
    "        \n",
    "    # CPU RAM в MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    ram_used = process.memory_info().rss / (1024 ** 2)\n",
    "    print(f\"CPU RAM used: {ram_used:.2f} MB\")\n",
    "    \n",
    "    # GPU VRAM в MB\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        vram_used = gpu.memoryUsed\n",
    "        vram_total = gpu.memoryTotal\n",
    "        print(f\"GPU {gpu.id} VRAM: {vram_used:.2f} MB / {vram_total:.2f} MB\")\n",
    "\n",
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    return (param_size + buffer_size) / 1024**2\n",
    "\n",
    "def calculate_metrics(model, device, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(targets.numpy())\n",
    "    \n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def load_imagenet_mini(dataset_path, model):\n",
    "    # Создаем трансформы на основе модели\n",
    "    config = resolve_data_config({}, model=model)\n",
    "    transform = create_transform(**config)\n",
    "    \n",
    "    # Загружаем датасет\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(dataset_path, 'val'),\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "def benchmark_model(model, device, input_tensor, num_runs=10, warmup=3, use_amp=False):\n",
    "    model = model.to(device)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"\\n🔥 Warming up ({warmup} runs) on {device}...\")\n",
    "    for _ in range(warmup):\n",
    "        with torch.no_grad():\n",
    "            if use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    _ = model(input_tensor)\n",
    "            else:\n",
    "                _ = model(input_tensor)\n",
    "    \n",
    "    # Benchmark\n",
    "    print(f\"🚀 Benchmarking ({num_runs} runs) on {device}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        with torch.no_grad():\n",
    "            if use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    _ = model(input_tensor)\n",
    "            else:\n",
    "                _ = model(input_tensor)\n",
    "    \n",
    "    total_time = (time.time() - start_time) * 1000\n",
    "    avg_time = total_time / num_runs\n",
    "    print(f\"✅ Average inference: {avg_time:.2f} ms\")\n",
    "    print(f\"📊 Total time: {total_time:.2f} ms | FPS: {1000/(avg_time + 1e-9):.1f}\")\n",
    "    \n",
    "    return avg_time\n",
    "\n",
    "def main(model, dataset_path=None):\n",
    "    device_cpu = torch.device('cpu')\n",
    "    device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(\"\\n🔍 Initial memory state:\")\n",
    "    print_memory_usage(\"Before loading model\")\n",
    "    model.eval()\n",
    "    print(f\"📏 Model size: {get_model_size(model):.2f} MB\")\n",
    "\n",
    "    print(\"\\n🔍 Initial memory state:\")\n",
    "    print_memory_usage(\"Model loaded\")\n",
    "    \n",
    "    # Бенчмарки\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)\n",
    "    \n",
    "    print(\"\\n🧪 Benchmarking on CPU:\")\n",
    "    cpu_time = benchmark_model(model, device_cpu, input_tensor)\n",
    "    print_memory_usage(\"After CPU benchmark\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\n🎮 Benchmarking on GPU:\")\n",
    "        gpu_time = benchmark_model(model, device_gpu, input_tensor)\n",
    "        print_memory_usage(\"After GPU test\")\n",
    "        \n",
    "        print(\"\\n⚡ Benchmarking with AMP:\")\n",
    "        gpu_amp_time = benchmark_model(model, device_gpu, input_tensor, use_amp=True)\n",
    "        print_memory_usage(\"After AMP test\")\n",
    "        \n",
    "        print(\"\\n📈 Results Summary:\")\n",
    "        print(f\"| Device | Inference Time (ms) | Speedup vs CPU |\")\n",
    "        print(\"|--------|---------------------|----------------|\")\n",
    "        print(f\"| CPU    | {cpu_time:19.2f} | {'—':^15} |\")\n",
    "        print(f\"| GPU    | {gpu_time:19.2f} | {cpu_time/gpu_time:^15.1f}x |\")\n",
    "        print(f\"| AMP    | {gpu_amp_time:19.2f} | {cpu_time/gpu_amp_time:^15.1f}x |\")\n",
    "    else:\n",
    "        print(\"\\n❌ CUDA not available\")\n",
    "        print(f\"⏱️ CPU inference time: {cpu_time:.2f} ms\")\n",
    "        if dataset_path:\n",
    "            print(\"\\n🎯 Quality Metrics (CPU):\")\n",
    "            print(f\"Precision: {precision_cpu:.4f}\")\n",
    "            print(f\"Recall:    {recall_cpu:.a4f}\")\n",
    "            print(f\"F1-Score:  {f1_cpu:.4f}\")\n",
    "\n",
    "    # Загрузка и расчет метрик качества\n",
    "    if dataset_path:\n",
    "        print(\"\\n📊 Loading ImageNetMini dataset...\")\n",
    "        data_loader = load_imagenet_mini(dataset_path, model)\n",
    "        \n",
    "        # print(\"\\n🧮 Calculating metrics on CPU:\")\n",
    "        # precision_cpu, recall_cpu, f1_cpu = calculate_metrics(model, device_cpu, data_loader)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            print(\"\\n🧮 Calculating metrics on GPU:\")\n",
    "            precision_gpu, recall_gpu, f1_gpu = calculate_metrics(model, device_gpu, data_loader)\n",
    "\n",
    "            print(\"\\n🎯 Quality Metrics Summary:\")\n",
    "            print(\"| Device | Precision | Recall  | F1-Score |\")\n",
    "            print(\"|--------|-----------|---------|----------|\")\n",
    "            # print(f\"| CPU    | {precision_cpu:.4f}  | {recall_cpu:.4f} | {f1_cpu:.4f}  |\")\n",
    "            print(f\"| GPU    | {precision_gpu:.4f}  | {recall_gpu:.4f} | {f1_gpu:.4f}  |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf6ef7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:08.949705Z",
     "iopub.status.busy": "2025-04-12T11:17:08.948900Z",
     "iopub.status.idle": "2025-04-12T11:17:09.219420Z",
     "shell.execute_reply": "2025-04-12T11:17:09.218630Z"
    },
    "papermill": {
     "duration": 0.384631,
     "end_time": "2025-04-12T11:17:09.220956",
     "exception": false,
     "start_time": "2025-04-12T11:17:08.836325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = timm.create_model('efficientvit_b1.r256_in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a339e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:09.444688Z",
     "iopub.status.busy": "2025-04-12T11:17:09.443947Z",
     "iopub.status.idle": "2025-04-12T11:17:32.238470Z",
     "shell.execute_reply": "2025-04-12T11:17:32.237454Z"
    },
    "papermill": {
     "duration": 22.905913,
     "end_time": "2025-04-12T11:17:32.239862",
     "exception": false,
     "start_time": "2025-04-12T11:17:09.333949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Initial memory state:\n",
      "\n",
      "--- Memory Usage (Before loading model) ---\n",
      "CPU RAM used: 1898.00 MB\n",
      "GPU 0 VRAM: 7747.00 MB / 16384.00 MB\n",
      "📏 Model size: 34.77 MB\n",
      "\n",
      "🔍 Initial memory state:\n",
      "\n",
      "--- Memory Usage (Model loaded) ---\n",
      "CPU RAM used: 1898.00 MB\n",
      "GPU 0 VRAM: 7747.00 MB / 16384.00 MB\n",
      "\n",
      "🧪 Benchmarking on CPU:\n",
      "\n",
      "🔥 Warming up (3 runs) on cpu...\n",
      "🚀 Benchmarking (10 runs) on cpu...\n",
      "✅ Average inference: 30.29 ms\n",
      "📊 Total time: 302.87 ms | FPS: 33.0\n",
      "\n",
      "--- Memory Usage (After CPU benchmark) ---\n",
      "CPU RAM used: 1927.25 MB\n",
      "GPU 0 VRAM: 7747.00 MB / 16384.00 MB\n",
      "\n",
      "🎮 Benchmarking on GPU:\n",
      "\n",
      "🔥 Warming up (3 runs) on cuda...\n",
      "🚀 Benchmarking (10 runs) on cuda...\n",
      "✅ Average inference: 11.21 ms\n",
      "📊 Total time: 112.12 ms | FPS: 89.2\n",
      "\n",
      "--- Memory Usage (After GPU test) ---\n",
      "CPU RAM used: 1928.25 MB\n",
      "GPU 0 VRAM: 7753.00 MB / 16384.00 MB\n",
      "\n",
      "⚡ Benchmarking with AMP:\n",
      "\n",
      "🔥 Warming up (3 runs) on cuda...\n",
      "🚀 Benchmarking (10 runs) on cuda...\n",
      "✅ Average inference: 13.90 ms\n",
      "📊 Total time: 138.98 ms | FPS: 72.0\n",
      "\n",
      "--- Memory Usage (After AMP test) ---\n",
      "CPU RAM used: 1933.00 MB\n",
      "GPU 0 VRAM: 7759.00 MB / 16384.00 MB\n",
      "\n",
      "📈 Results Summary:\n",
      "| Device | Inference Time (ms) | Speedup vs CPU |\n",
      "|--------|---------------------|----------------|\n",
      "| CPU    |               30.29 |        —        |\n",
      "| GPU    |               11.21 |       2.7      x |\n",
      "| AMP    |               13.90 |       2.2      x |\n",
      "\n",
      "📊 Loading ImageNetMini dataset...\n",
      "\n",
      "🧮 Calculating metrics on GPU:\n",
      "\n",
      "🎯 Quality Metrics Summary:\n",
      "| Device | Precision | Recall  | F1-Score |\n",
      "|--------|-----------|---------|----------|\n",
      "| GPU    | 0.8150  | 0.7993 | 0.7874  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main(base_model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b03fa70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:32.468574Z",
     "iopub.status.busy": "2025-04-12T11:17:32.467591Z",
     "iopub.status.idle": "2025-04-12T11:17:32.780582Z",
     "shell.execute_reply": "2025-04-12T11:17:32.779888Z"
    },
    "papermill": {
     "duration": 0.426562,
     "end_time": "2025-04-12T11:17:32.781858",
     "exception": false,
     "start_time": "2025-04-12T11:17:32.355296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = timm.create_model('efficientvit_b1.r256_in1k', pretrained=True)\n",
    "trained_model.load_state_dict(torch.load('best_model.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704186bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T11:17:33.004637Z",
     "iopub.status.busy": "2025-04-12T11:17:33.004110Z",
     "iopub.status.idle": "2025-04-12T11:17:49.589240Z",
     "shell.execute_reply": "2025-04-12T11:17:49.587819Z"
    },
    "papermill": {
     "duration": 16.697234,
     "end_time": "2025-04-12T11:17:49.590626",
     "exception": false,
     "start_time": "2025-04-12T11:17:32.893392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Initial memory state:\n",
      "\n",
      "--- Memory Usage (Before loading model) ---\n",
      "CPU RAM used: 1965.47 MB\n",
      "GPU 0 VRAM: 7765.00 MB / 16384.00 MB\n",
      "📏 Model size: 34.77 MB\n",
      "\n",
      "🔍 Initial memory state:\n",
      "\n",
      "--- Memory Usage (Model loaded) ---\n",
      "CPU RAM used: 1965.47 MB\n",
      "GPU 0 VRAM: 7765.00 MB / 16384.00 MB\n",
      "\n",
      "🧪 Benchmarking on CPU:\n",
      "\n",
      "🔥 Warming up (3 runs) on cpu...\n",
      "🚀 Benchmarking (10 runs) on cpu...\n",
      "✅ Average inference: 32.00 ms\n",
      "📊 Total time: 320.03 ms | FPS: 31.2\n",
      "\n",
      "--- Memory Usage (After CPU benchmark) ---\n",
      "CPU RAM used: 1965.47 MB\n",
      "GPU 0 VRAM: 7765.00 MB / 16384.00 MB\n",
      "\n",
      "🎮 Benchmarking on GPU:\n",
      "\n",
      "🔥 Warming up (3 runs) on cuda...\n",
      "🚀 Benchmarking (10 runs) on cuda...\n",
      "✅ Average inference: 10.82 ms\n",
      "📊 Total time: 108.18 ms | FPS: 92.4\n",
      "\n",
      "--- Memory Usage (After GPU test) ---\n",
      "CPU RAM used: 1965.47 MB\n",
      "GPU 0 VRAM: 7769.00 MB / 16384.00 MB\n",
      "\n",
      "⚡ Benchmarking with AMP:\n",
      "\n",
      "🔥 Warming up (3 runs) on cuda...\n",
      "🚀 Benchmarking (10 runs) on cuda...\n",
      "✅ Average inference: 13.36 ms\n",
      "📊 Total time: 133.61 ms | FPS: 74.8\n",
      "\n",
      "--- Memory Usage (After AMP test) ---\n",
      "CPU RAM used: 1965.47 MB\n",
      "GPU 0 VRAM: 7777.00 MB / 16384.00 MB\n",
      "\n",
      "📈 Results Summary:\n",
      "| Device | Inference Time (ms) | Speedup vs CPU |\n",
      "|--------|---------------------|----------------|\n",
      "| CPU    |               32.00 |        —        |\n",
      "| GPU    |               10.82 |       3.0      x |\n",
      "| AMP    |               13.36 |       2.4      x |\n",
      "\n",
      "📊 Loading ImageNetMini dataset...\n",
      "\n",
      "🧮 Calculating metrics on GPU:\n",
      "\n",
      "🎯 Quality Metrics Summary:\n",
      "| Device | Precision | Recall  | F1-Score |\n",
      "|--------|-----------|---------|----------|\n",
      "| GPU    | 0.7851  | 0.7655 | 0.7522  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main(trained_model, path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 547506,
     "sourceId": 998277,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4186.83842,
   "end_time": "2025-04-12T11:17:53.434592",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T10:08:06.596172",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01fc3b305e2042409c7fe2e690697432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_490362ef29654d009d534de784b0f33f",
       "placeholder": "​",
       "style": "IPY_MODEL_d00f80413bc6481e8ce02463805d2944",
       "tabbable": null,
       "tooltip": null,
       "value": " 36.5M/36.5M [00:00&lt;00:00, 272MB/s]"
      }
     },
     "14af2540c2944fbe9522cf7c33cd112f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "454c2a7d20044594b280c9e76383d2f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48ff3c632ac3456d885c8d52e3087bff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "490362ef29654d009d534de784b0f33f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53bbeb2ed187481c9d597ddecf696bde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f262928adca4f0083988ff758605784": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6fd442de3f5c45cf8dc1fdcdfaa05c1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "767b021b574c4bcabf011d5067ace668": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "979dfc7c01d84a1c8dd0b293a7384abf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e674f6b74e64dc780f3c1587b05d083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca03b79855bf4490ba30de767a6cee25",
       "placeholder": "​",
       "style": "IPY_MODEL_5f262928adca4f0083988ff758605784",
       "tabbable": null,
       "tooltip": null,
       "value": " 195M/195M [00:00&lt;00:00, 309MB/s]"
      }
     },
     "ad4f5c6c87194788b0616468c00f87e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_454c2a7d20044594b280c9e76383d2f2",
       "placeholder": "​",
       "style": "IPY_MODEL_48ff3c632ac3456d885c8d52e3087bff",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "c0c9dd779e6d49a383c80726f6cd15f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c28b978d4ef94b7496dc79f66d64720a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53bbeb2ed187481c9d597ddecf696bde",
       "max": 36494688.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_14af2540c2944fbe9522cf7c33cd112f",
       "tabbable": null,
       "tooltip": null,
       "value": 36494688.0
      }
     },
     "c3f45ccc457c426289ce1eedb2b0b019": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca03b79855bf4490ba30de767a6cee25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfcf15f124694047a23b06b495a38faf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dcda8b2ea78649998378156689d2af63",
       "max": 194838984.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0c9dd779e6d49a383c80726f6cd15f0",
       "tabbable": null,
       "tooltip": null,
       "value": 194838984.0
      }
     },
     "d00f80413bc6481e8ce02463805d2944": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d48ef0daa0ef4ef9b87481dce0959857": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad4f5c6c87194788b0616468c00f87e6",
        "IPY_MODEL_cfcf15f124694047a23b06b495a38faf",
        "IPY_MODEL_9e674f6b74e64dc780f3c1587b05d083"
       ],
       "layout": "IPY_MODEL_6fd442de3f5c45cf8dc1fdcdfaa05c1e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dcda8b2ea78649998378156689d2af63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e51afa35b12e49d4a7fea522ed38ed36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_edb7b9108b804efa9126002164755e47",
        "IPY_MODEL_c28b978d4ef94b7496dc79f66d64720a",
        "IPY_MODEL_01fc3b305e2042409c7fe2e690697432"
       ],
       "layout": "IPY_MODEL_979dfc7c01d84a1c8dd0b293a7384abf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "edb7b9108b804efa9126002164755e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_767b021b574c4bcabf011d5067ace668",
       "placeholder": "​",
       "style": "IPY_MODEL_c3f45ccc457c426289ce1eedb2b0b019",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
