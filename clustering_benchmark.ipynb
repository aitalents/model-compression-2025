{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":998277,"datasetId":547506,"databundleVersionId":1026923}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install GPUtil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:40.076803Z","iopub.execute_input":"2025-04-24T08:59:40.077232Z","iopub.status.idle":"2025-04-24T08:59:43.388078Z","shell.execute_reply.started":"2025-04-24T08:59:40.077206Z","shell.execute_reply":"2025-04-24T08:59:43.387414Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: GPUtil in /usr/local/lib/python3.11/dist-packages (1.4.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport psutil\nimport GPUtil\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nimport timm\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform\nfrom torchvision import datasets, transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:43.394410Z","iopub.execute_input":"2025-04-24T08:59:43.394689Z","iopub.status.idle":"2025-04-24T08:59:48.475729Z","shell.execute_reply.started":"2025-04-24T08:59:43.394657Z","shell.execute_reply":"2025-04-24T08:59:48.475124Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import kagglehub\npath = kagglehub.dataset_download(\"ifigotin/imagenetmini-1000\")\npath += \"/imagenet-mini\"\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.479372Z","iopub.execute_input":"2025-04-24T08:59:48.479567Z","iopub.status.idle":"2025-04-24T08:59:48.772840Z","shell.execute_reply.started":"2025-04-24T08:59:48.479550Z","shell.execute_reply":"2025-04-24T08:59:48.772199Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/imagenetmini-1000/imagenet-mini\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def load_imagenet_mini(dataset_path, model):\n    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏\n    config = resolve_data_config({}, model=model)\n    transform = create_transform(**config)\n    \n    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n    dataset = datasets.ImageFolder(\n        root=os.path.join(dataset_path, 'val'),\n        transform=transform\n    )\n    \n    data_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=64,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n    )\n    \n    return data_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.791814Z","iopub.execute_input":"2025-04-24T08:59:48.792025Z","iopub.status.idle":"2025-04-24T08:59:48.796645Z","shell.execute_reply.started":"2025-04-24T08:59:48.792009Z","shell.execute_reply":"2025-04-24T08:59:48.796041Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def print_memory_usage():\n    proc = psutil.Process(os.getpid())\n    ram = proc.memory_info().rss / 1024**2\n    gpus = GPUtil.getGPUs()\n    vram = sum(g.memoryUsed for g in gpus)\n    return ram, vram","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.797294Z","iopub.execute_input":"2025-04-24T08:59:48.797499Z","iopub.status.idle":"2025-04-24T08:59:48.814261Z","shell.execute_reply.started":"2025-04-24T08:59:48.797476Z","shell.execute_reply":"2025-04-24T08:59:48.813608Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def benchmark_model(model, device, input_tensor, num_runs=10, warmup=3, use_amp=False):\n    model = model.to(device)\n    input_tensor = input_tensor.to(device)\n    \n    # Warmup\n    print(f\"\\nüî• Warming up ({warmup} runs) on {device}...\")\n    for _ in range(warmup):\n        with torch.no_grad():\n            if use_amp and device.type == 'cuda':\n                with autocast(device_type='cuda', dtype=torch.float16):\n                    _ = model(input_tensor)\n            else:\n                _ = model(input_tensor)\n    \n    # Benchmark\n    print(f\"üöÄ Benchmarking ({num_runs} runs) on {device}...\")\n    start_time = time.time()\n    \n    for _ in range(num_runs):\n        with torch.no_grad():\n            if use_amp and device.type == 'cuda':\n                with autocast(device_type='cuda', dtype=torch.float16):\n                    _ = model(input_tensor)\n            else:\n                _ = model(input_tensor)\n    \n    total_time = (time.time() - start_time) * 1000\n    avg_time = total_time / num_runs\n    print(f\"‚úÖ Average inference: {avg_time:.2f} ms\")\n    print(f\"üìä Total time: {total_time:.2f} ms | FPS: {1000/(avg_time + 1e-9):.1f}\")\n    \n    return avg_time\n\ndef get_model_size(model):\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.nelement() * param.element_size()\n    buffer_size = 0\n    for buffer in model.buffers():\n        buffer_size += buffer.nelement() * buffer.element_size()\n    return (param_size + buffer_size) / 1024**2\n\ndef calculate_metrics(model, device, data_loader):\n    model.eval()\n    all_preds = []\n    all_targets = []\n\n    model.to(device)\n    with torch.no_grad():\n        for images, targets in data_loader:\n            images = images.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(dim=1).cpu().numpy()\n            \n            all_preds.extend(preds)\n            all_targets.extend(targets.numpy())\n    \n    precision = precision_score(all_targets, all_preds, average='macro')\n    recall = recall_score(all_targets, all_preds, average='macro')\n    f1 = f1_score(all_targets, all_preds, average='macro')\n    \n    return precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.818647Z","iopub.execute_input":"2025-04-24T08:59:48.818904Z","iopub.status.idle":"2025-04-24T08:59:48.829911Z","shell.execute_reply.started":"2025-04-24T08:59:48.818881Z","shell.execute_reply":"2025-04-24T08:59:48.829345Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"input_tensor = torch.randn(1, 3, 224, 224)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.830596Z","iopub.execute_input":"2025-04-24T08:59:48.830873Z","iopub.status.idle":"2025-04-24T08:59:48.849267Z","shell.execute_reply.started":"2025-04-24T08:59:48.830845Z","shell.execute_reply":"2025-04-24T08:59:48.848650Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = timm.create_model('efficientvit_b3.r256_in1k', pretrained=True).eval()\nloader = load_imagenet_mini(dataset_path=path, model=model)\nbaseline_size  = get_model_size(model)\nbaseline_cpu   = benchmark_model(model, torch.device('cpu'),  input_tensor)\nbaseline_gpu   = benchmark_model(model, torch.device('cuda'), input_tensor)\nbaseline_prec, baseline_rec, baseline_f1 = calculate_metrics(model, torch.device('cuda'), loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:59:48.849945Z","iopub.execute_input":"2025-04-24T08:59:48.850144Z","iopub.status.idle":"2025-04-24T09:00:11.263971Z","shell.execute_reply.started":"2025-04-24T08:59:48.850127Z","shell.execute_reply":"2025-04-24T09:00:11.262883Z"}},"outputs":[{"name":"stdout","text":"\nüî• Warming up (3 runs) on cpu...\nüöÄ Benchmarking (10 runs) on cpu...\n‚úÖ Average inference: 121.76 ms\nüìä Total time: 1217.61 ms | FPS: 8.2\n\nüî• Warming up (3 runs) on cuda...\nüöÄ Benchmarking (10 runs) on cuda...\n‚úÖ Average inference: 22.19 ms\nüìä Total time: 221.87 ms | FPS: 45.1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\nfrom tqdm import tqdm\n\ndef cluster_model_weights(model, k=32, skip_prefix=('stem', 'head.')):\n    \"\"\"–ó–∞–º–µ–Ω—è–µ—Ç –≤–µ—Å–∞ –Ω–∞ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫—É —Å–∂–∞—Ç–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.\"\"\"\n    compressed_bytes = 0\n    model.cpu()\n\n    with torch.no_grad():\n        for name, p in tqdm(model.named_parameters(), desc=\"Clustering\"):\n            if p.dim() < 2 or name.startswith(skip_prefix):\n                continue                            # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º bias, stem, head\n\n            flat = p.detach().reshape(-1, 1).float().numpy()\n            k_here = min(k, len(flat))\n            kmeans = MiniBatchKMeans(k_here, batch_size=4096,\n                                     max_iter=100, n_init='auto',\n                                     random_state=0).fit(flat)\n            \n            centers = torch.tensor(kmeans.cluster_centers_.squeeze(),\n                                   dtype=p.dtype)\n            labels  = torch.from_numpy(kmeans.labels_).long()\n            \n            p.copy_(centers[labels].reshape_as(p))\n\n            # —Å—á–∏—Ç–∞–µ–º –æ–±—ä—ë–º ¬´–∏–Ω–¥–µ–∫—Å—ã + —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã¬ª\n            compressed_bytes += labels.numel()            # uint8 ‚Üí 1 –±–∞–π—Ç\n            compressed_bytes += centers.numel() * 4       # float32 ‚Üí 4 –±–∞–π—Ç–∞\n\n    return compressed_bytes / 1_048_576                   # ‚Üí –ú–ë","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:00:11.266056Z","iopub.execute_input":"2025-04-24T09:00:11.266330Z","iopub.status.idle":"2025-04-24T09:00:11.274165Z","shell.execute_reply.started":"2025-04-24T09:00:11.266306Z","shell.execute_reply":"2025-04-24T09:00:11.273437Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"compressed_size = cluster_model_weights(model, k=32)\n\ncluster_cpu  = benchmark_model(model, torch.device('cpu'),  input_tensor)\ncluster_gpu  = benchmark_model(model, torch.device('cuda'), input_tensor)\n\nprint(f\"–°–∂–∞—Ç—ã–π —Ä–∞–∑–º–µ—Ä: {compressed_size:.2f} MB  \"\n      f\"(–±—ã–ª–æ {baseline_size:.2f} MB)\")\nprint(f\"CPU {baseline_cpu:.1f} ‚Üí {cluster_cpu:.1f} ms   \"\n      f\"GPU {baseline_gpu:.1f} ‚Üí {cluster_gpu:.1f} ms\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:03:04.760748Z","iopub.execute_input":"2025-04-24T09:03:04.761303Z","iopub.status.idle":"2025-04-24T09:03:13.538162Z","shell.execute_reply.started":"2025-04-24T09:03:04.761276Z","shell.execute_reply":"2025-04-24T09:03:13.537563Z"}},"outputs":[{"name":"stderr","text":"Clustering: 316it [00:06, 46.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nüî• Warming up (3 runs) on cpu...\nüöÄ Benchmarking (10 runs) on cpu...\n‚úÖ Average inference: 116.38 ms\nüìä Total time: 1163.82 ms | FPS: 8.6\n\nüî• Warming up (3 runs) on cuda...\nüöÄ Benchmarking (10 runs) on cuda...\n‚úÖ Average inference: 22.30 ms\nüìä Total time: 223.03 ms | FPS: 44.8\n–°–∂–∞—Ç—ã–π —Ä–∞–∑–º–µ—Ä: 37.11 MB  (–±—ã–ª–æ 185.75 MB)\nCPU 121.8 ‚Üí 106.4 ms   GPU 22.2 ‚Üí 21.8 ms\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}